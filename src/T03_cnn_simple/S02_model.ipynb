{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ab4d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10af9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # First convolutional layer:\n",
    "        # - Input channels: 1 (for grayscale images; use 3 for RGB),\n",
    "        # - Output channels: 16 feature maps,\n",
    "        # - Kernel size: 3x3,\n",
    "        # - Padding: 1 (to preserve spatial dimensions)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "\n",
    "        # Second convolutional layer:\n",
    "        # - Input channels: 16 (from previous layer),\n",
    "        # - Output channels: 32,\n",
    "        # - Kernel size: 3x3,\n",
    "        # - Padding: 1\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling layer with a 2x2 window (reduces feature map size by half)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Non-linear activation function (introduces non-linearity)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Adaptive average pooling to output 4x4 feature maps (regardless of original input size)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "\n",
    "        # Fully connected layer for classification:\n",
    "        # - Input size: 32 feature maps * 4 * 4 (from adaptive pooling)\n",
    "        # - Output size: number of classes\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Pass input through the first convolutional layer\n",
    "        X = self.conv1(X)\n",
    "        X = self.relu(X)  # Apply ReLU activation\n",
    "        X = self.max_pool(X)  # Apply max pooling\n",
    "\n",
    "        # Pass through the second convolutional layer\n",
    "        X = self.conv2(X)\n",
    "        X = self.relu(X)  # Apply ReLU activation\n",
    "        X = self.max_pool(X)  # Apply max pooling\n",
    "\n",
    "        # Apply adaptive average pooling to standardize feature map size\n",
    "        X = self.adaptive_pool(X)\n",
    "\n",
    "        # Flatten the output to a 1D tensor for the fully connected layer\n",
    "        X = X.view(X.shape[0], -1)\n",
    "\n",
    "        # Pass through the fully connected layer to get final class scores\n",
    "        X = self.fc1(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "model = SimpleCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6755ea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleCNN                                [100, 10]                 --\n",
       "├─Conv2d: 1-1                            [100, 16, 32, 32]         160\n",
       "├─ReLU: 1-2                              [100, 16, 32, 32]         --\n",
       "├─MaxPool2d: 1-3                         [100, 16, 16, 16]         --\n",
       "├─Conv2d: 1-4                            [100, 32, 16, 16]         4,640\n",
       "├─ReLU: 1-5                              [100, 32, 16, 16]         --\n",
       "├─MaxPool2d: 1-6                         [100, 32, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d: 1-7                 [100, 32, 4, 4]           --\n",
       "├─Linear: 1-8                            [100, 10]                 5,130\n",
       "==========================================================================================\n",
       "Total params: 9,930\n",
       "Trainable params: 9,930\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 135.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.41\n",
       "Forward/backward pass size (MB): 19.67\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 20.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "input_size = (100, 1, 32, 32)  # (batch_size, channels, height, width)\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e804b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "batch_size = 100\n",
    "X = torch.randn(batch_size, 1, 28, 28)\n",
    "Y = model(X)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e0fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
