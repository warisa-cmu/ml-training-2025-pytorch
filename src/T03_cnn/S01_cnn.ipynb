{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd55ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pt_runner.cnn import CheckpointHandler, DataHandlerPT, EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc5cecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New run\n",
    "NEW_RUN = True\n",
    "DT_REF = None\n",
    "\n",
    "# Resuming\n",
    "# NEW_RUN = False\n",
    "# DT_REF = \"2025-05-28_10-43\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "015c23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac2a5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_small.pickle\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e69a838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1, 28, 28)\n",
      "float64\n",
      "(2000, 1)\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "_X = data[\"_X\"].astype(np.float64)\n",
    "_Y = data[\"_Y\"].astype(np.int32)\n",
    "print(_X.shape)\n",
    "print(_X.dtype)\n",
    "print(_Y.shape)\n",
    "print(_Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ad4548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandlerPT(_X=_X, _Y=_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f511d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4285,  0.5164, -0.1503, -0.3107, -0.2864, -0.1454, -0.2039, -0.3829,\n",
       "          0.4990,  0.0946],\n",
       "        [ 0.4150,  0.5385, -0.1328, -0.2854, -0.2999, -0.1560, -0.2194, -0.4265,\n",
       "          0.5209,  0.0918],\n",
       "        [ 0.3686,  0.5573, -0.1741, -0.2945, -0.2798, -0.1405, -0.2148, -0.4065,\n",
       "          0.4198,  0.1498],\n",
       "        [ 0.4004,  0.5316, -0.1958, -0.3578, -0.3306, -0.1335, -0.2337, -0.3938,\n",
       "          0.4864,  0.0839],\n",
       "        [ 0.4165,  0.5287, -0.1768, -0.3492, -0.3555, -0.1698, -0.2517, -0.4273,\n",
       "          0.4986,  0.0974],\n",
       "        [ 0.4087,  0.4957, -0.1275, -0.3625, -0.3103, -0.1728, -0.2275, -0.3894,\n",
       "          0.4445,  0.0719],\n",
       "        [ 0.3778,  0.5421, -0.1936, -0.3965, -0.3241, -0.1704, -0.2628, -0.3800,\n",
       "          0.5135,  0.0715],\n",
       "        [ 0.3977,  0.5377, -0.1756, -0.3325, -0.3044, -0.1376, -0.2335, -0.4195,\n",
       "          0.4738,  0.1065],\n",
       "        [ 0.3839,  0.5326, -0.1739, -0.2993, -0.3323, -0.1688, -0.2065, -0.4378,\n",
       "          0.4514,  0.0785],\n",
       "        [ 0.3627,  0.5266, -0.1569, -0.3018, -0.3279, -0.1534, -0.2206, -0.3984,\n",
       "          0.4345,  0.0876]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # First convolutional layer: input channels=3 (e.g., RGB), output channels=16, kernel size=3\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, num_classes)  # Adjust input size depending on image size!\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 1st Conv + Activation + Pooling\n",
    "        X = self.conv1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.max_pool(X)\n",
    "        # 2nd Conv + Activation + Pooling\n",
    "        X = self.conv2(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.max_pool(X)\n",
    "\n",
    "        X = self.adaptive_pool(X)\n",
    "        # Flatten the output for the fully connected layer\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        # Fully connected output\n",
    "        X = self.fc1(X)\n",
    "        return X\n",
    "\n",
    "model = SimpleCNN(num_classes=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Test\n",
    "X = torch.randn(10,1, 28,28)\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "302994cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleCNN                                [100, 10]                 --\n",
       "├─Conv2d: 1-1                            [100, 16, 32, 32]         160\n",
       "├─ReLU: 1-2                              [100, 16, 32, 32]         --\n",
       "├─MaxPool2d: 1-3                         [100, 16, 16, 16]         --\n",
       "├─Conv2d: 1-4                            [100, 32, 16, 16]         4,640\n",
       "├─ReLU: 1-5                              [100, 32, 16, 16]         --\n",
       "├─MaxPool2d: 1-6                         [100, 32, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d: 1-7                 [100, 32, 4, 4]           --\n",
       "├─Linear: 1-8                            [100, 10]                 5,130\n",
       "==========================================================================================\n",
       "Total params: 9,930\n",
       "Trainable params: 9,930\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 135.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.41\n",
       "Forward/backward pass size (MB): 19.67\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 20.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "input_size = (100, 1, 32, 32) # (batch_size, channels, height, width)\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22a25d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55fd0420e3042a6ae48176189f1d696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model @ epoch: 0\n",
      "Save model @ epoch: 10\n",
      "Stopped at epoch: 110\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000  # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "validation_interval = 10  # Evaluate every 100 epochs\n",
    "log_name = \"M1\"\n",
    "random_state = 0  # Split data\n",
    "\n",
    "# Save/load\n",
    "cph = CheckpointHandler()\n",
    "cph.make_dir(\"./checkpoints\")\n",
    "if NEW_RUN:\n",
    "    dt = cph.get_dt()\n",
    "    log_dir = f\"runs/{dt}\"\n",
    "    save_path = f\"./checkpoints/{dt}.pth\"\n",
    "    epoch_start = 0\n",
    "else:\n",
    "    log_dir = f\"runs/{DT_REF}\"\n",
    "    load_path = f\"./checkpoints/{DT_REF}.pth\"\n",
    "    save_path = load_path\n",
    "    model, optimizer, epoch, val_loss = cph.load(\n",
    "        load_path=load_path, model=model, optimizer=optimizer\n",
    "    )\n",
    "    epoch_start = epoch\n",
    "    print(f\"Resuming from epoch: {epoch}\")\n",
    "\n",
    "epoch_end = epoch_start + n_epochs\n",
    "\n",
    "# Initialize Components\n",
    "early_stopper = EarlyStopper(patience=10)\n",
    "writer = SummaryWriter(log_dir=log_dir, purge_step=epoch_start)\n",
    "\n",
    "# Data\n",
    "data_handler.split_and_scale(test_size=0.2, val_size=0.1, random_state=RANDOM_STATE)\n",
    "ds_train = data_handler.get_train()\n",
    "ds_test = data_handler.get_test()\n",
    "ds_val = data_handler.get_val()\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Main loop\n",
    "for epoch in tqdm(\n",
    "    range(epoch_start, epoch_end), initial=epoch_start, desc=\"Epoch\", total=n_epochs\n",
    "):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "\n",
    "    for X_batch, Y_batch in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "        loss = loss_fn(Y_pred, Y_batch.view(-1))\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Multiplies the average loss per sample by the number of\n",
    "        # samples in the batch to get the total loss for this batch.\n",
    "        epoch_train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(loader_train.dataset)\n",
    "\n",
    "    # Validation Phase\n",
    "    if epoch % validation_interval == 0 or epoch == epoch_start:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, Y_val in loader_val:\n",
    "                Y_pred = model(X_val)\n",
    "                val_loss += loss_fn(Y_pred, Y_val.view(-1)).item() * X_val.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(loader_val.dataset)\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early Stopping and Checkpoint\n",
    "        es = early_stopper(avg_val_loss)\n",
    "        if es[\"best_loss\"]:\n",
    "            cph.save(\n",
    "                save_path=save_path,\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                val_loss=avg_val_loss,\n",
    "                epoch=epoch,\n",
    "            )\n",
    "            print(\"Save model @ epoch:\", epoch)\n",
    "        if es[\"early_stop\"]:\n",
    "            print(\"Stopped at epoch:\", epoch)\n",
    "            break\n",
    "\n",
    "        writer.add_scalars(\n",
    "            log_name, {\"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss}, epoch\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05614dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pt_runner.cnn.DatasetPT at 0x14180231e50>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcb76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
