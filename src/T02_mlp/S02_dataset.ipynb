{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "33eb9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0955e",
   "metadata": {},
   "source": [
    "### What is the PyTorch Dataset class?\n",
    "\n",
    "The PyTorch Dataset class is a base class (called `torch.utils.data.Dataset`) that provides an easy way to work with and load data in PyTorch, especially for training and evaluating machine learning models.\n",
    "\n",
    "Main Purpose\n",
    "It helps you:\n",
    "\n",
    "- Organize your data (images, text, etc.).\n",
    "- Provide a standardized way to access each data point and its label.\n",
    "- Work efficiently with the `DataLoader` for batching, shuffling, and parallel loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a15da988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the total number of samples\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Returns the data and label at index idx\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c85c5530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.],\n",
      "        [ 1.,  2.],\n",
      "        [ 2.,  3.],\n",
      "        [ 3.,  4.],\n",
      "        [ 4.,  5.],\n",
      "        [ 5.,  6.],\n",
      "        [ 6.,  7.],\n",
      "        [ 7.,  8.],\n",
      "        [ 8.,  9.],\n",
      "        [ 9., 10.]])\n",
      "tensor([ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19.])\n"
     ]
    }
   ],
   "source": [
    "# Features: 10 samples, each with 2 numbers\n",
    "features = torch.tensor([[i, i + 1] for i in range(10)], dtype=torch.float32)\n",
    "\n",
    "# Labels: 10 numbers (e.g., sum of the features for demonstration)\n",
    "labels = torch.tensor([i + (i + 1) for i in range(10)], dtype=torch.float32)\n",
    "\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d86641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(tensor([0., 1.]), tensor(1.))\n",
      "(tensor([[0., 1.],\n",
      "        [1., 2.],\n",
      "        [2., 3.]]), tensor([1., 3., 5.]))\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of your custom dataset with features and labels\n",
    "dataset = MyCustomDataset(features, labels)\n",
    "\n",
    "# Print the total number of samples in the dataset\n",
    "print(len(dataset))\n",
    "\n",
    "# Print the first data sample and its label (index 0)\n",
    "print(dataset[0])\n",
    "\n",
    "# Print a slice of the dataset (from index 0 up to, but not including, index 3)\n",
    "print(dataset[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23651f2",
   "metadata": {},
   "source": [
    "### What is PyTorch DataLoader?\n",
    "\n",
    "The PyTorch DataLoader is a convenient tool that helps you load data efficiently during model training or evaluation. It works together with a Dataset to provide batches of data, handles shuffling, and can load data in parallel to speed up training.\n",
    "\n",
    "Key Features\n",
    "- Batches your data automatically (e.g., batch size of 32 means you get 32 samples at a time).\n",
    "- Shuffles your data if needed, which helps prevent the model from learning the order.\n",
    "- Loads data in parallel with multiple worker processes for speed (especially useful for large datasets).\n",
    "- Iterates easily through your dataset, so you don’t have to write custom loops for slicing or batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75631e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features: tensor([[3., 4.],\n",
      "        [1., 2.],\n",
      "        [6., 7.]])\n",
      "Batch labels: tensor([ 7.,  3., 13.])\n",
      "---\n",
      "Batch features: tensor([[ 0.,  1.],\n",
      "        [ 9., 10.],\n",
      "        [ 5.,  6.]])\n",
      "Batch labels: tensor([ 1., 19., 11.])\n",
      "---\n",
      "Batch features: tensor([[2., 3.],\n",
      "        [7., 8.],\n",
      "        [8., 9.]])\n",
      "Batch labels: tensor([ 5., 15., 17.])\n",
      "---\n",
      "Batch features: tensor([[4., 5.]])\n",
      "Batch labels: tensor([9.])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader to load data from the dataset in batches of size 3, shuffling the data each epoch\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "# Loop through the DataLoader, which yields batches of features and labels\n",
    "for batch_features, batch_labels in dataloader:\n",
    "    print(\"Batch features:\", batch_features)\n",
    "    print(\"Batch labels:\", batch_labels)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7eff2f",
   "metadata": {},
   "source": [
    "### Let's write a custom dataset\n",
    "\n",
    "This dataset receives numpy arrays and returns PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0a0f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetPT(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_out = torch.from_numpy(self.X[idx, :]).float()\n",
    "        Y_out = torch.from_numpy(self.Y[idx, :]).float()\n",
    "        return X_out, Y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19640806",
   "metadata": {},
   "source": [
    "### Custom DataHandler\n",
    "\n",
    "- Stores Raw Data and Scalers\n",
    "    - Takes in raw feature data (_X), target values (_Y), and scaling objects (scalerX, scalerY)—these could be, for example, StandardScaler or MinMaxScaler from scikit-learn.\n",
    "Stores both the data and the scalers as attributes.\n",
    "- Splits and Scales Data\n",
    "    - `split_and_scale(test_size, random_state, val_size=0)`\n",
    "        - Splits the data into training, test, and (optionally) validation sets.\n",
    "        - Scales each set using the provided scalers.\n",
    "        - The scalers are fit on the training data and then transform all parts.\n",
    "    - Handles the validation split correctly, so you get exactly the fractions you want (e.g., 80% train, 10% val, 10% test).\n",
    "- Prepares PyTorch Datasets\n",
    "    - Methods get_train(), get_val(), and get_test() wrap each data split into a DatasetPT—your custom Dataset class from earlier. This makes the data easy to feed into PyTorch DataLoader objects.\n",
    "    - If validation data isn’t present, get_val() will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "853efa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandlerPT(Dataset):\n",
    "    def __init__(self, _X, _Y, scalerX, scalerY):\n",
    "        self._X = _X\n",
    "        self._Y = _Y\n",
    "        self.scalerX = scalerX\n",
    "        self.scalerY = scalerY\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.X_val = None\n",
    "        self.Y_train = None\n",
    "        self.Y_val = None\n",
    "        self.Y_test = None\n",
    "\n",
    "    def split_and_scale(self, test_size, random_state, val_size=0):\n",
    "        _X_train, _X_test, _Y_train, _Y_test = train_test_split(\n",
    "            self._X, self._Y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        self.scalerX.fit(_X_train)\n",
    "        self.scalerY.fit(_Y_train)\n",
    "\n",
    "        if val_size > 0:\n",
    "            _X_train, _X_val, _Y_train, _Y_val = train_test_split(\n",
    "                _X_train,\n",
    "                _Y_train,\n",
    "                # For example, if you want 80% train, 10% validation, and 10% test:\n",
    "                # First, split off the test set (10%):\n",
    "                # Next, split the remaining 90% into train and validation.\n",
    "                # Since you want 80% train and 10% validation overall, the validation set should be 10/90 = 0.111 of the remaining data.\n",
    "                test_size=val_size / (1 - test_size),\n",
    "                random_state=random_state + 100,  # Just make random_state different.\n",
    "            )\n",
    "            self.X_val = self.scalerX.transform(_X_val)\n",
    "            self.Y_val = self.scalerY.transform(_Y_val)\n",
    "\n",
    "        self.X_train = self.scalerX.transform(_X_train)\n",
    "        self.X_test = self.scalerX.transform(_X_test)\n",
    "\n",
    "        self.Y_train = self.scalerY.transform(_Y_train)\n",
    "        self.Y_test = self.scalerY.transform(_Y_test)\n",
    "\n",
    "    # This part is different from SKLearn version\n",
    "    def get_train(self):\n",
    "        return DatasetPT(X=self.X_train, Y=self.Y_train)\n",
    "\n",
    "    def get_val(self):\n",
    "        if self.X_val is None:\n",
    "            raise Exception(\"No validation data\")\n",
    "        return DatasetPT(X=self.X_val, Y=self.Y_val)\n",
    "\n",
    "    def get_test(self):\n",
    "        return DatasetPT(X=self.X_test, Y=self.Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c90f71a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10]) torch.Size([16, 2]) tensor([0.1232, 0.4645])\n",
      "torch.Size([16, 10]) torch.Size([16, 2]) tensor([0.2797, 0.5817])\n",
      "torch.Size([16, 10]) torch.Size([16, 2]) tensor([0.5345, 0.4246])\n",
      "torch.Size([16, 10]) torch.Size([16, 2]) tensor([0.8217, 0.5479])\n",
      "torch.Size([16, 10]) torch.Size([16, 2]) tensor([0.8011, 0.5184])\n",
      "torch.Size([16, 10]) torch.Size([16, 2]) tensor([0.4499, 0.2271])\n",
      "torch.Size([4, 10]) torch.Size([4, 2]) tensor([0.7141, 0.5166])\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use Pytorch Dataset and DataLoader classes\n",
    "X = np.random.rand(100, 10)  # 100 samples, 10 features each\n",
    "Y = np.random.rand(100, 2)  # 100 targets\n",
    "\n",
    "ds = DatasetPT(X, Y)\n",
    "loader = DataLoader(ds, batch_size=16, shuffle=True)\n",
    "\n",
    "for X_batch, Y_batch in loader:\n",
    "    print(X_batch.shape, Y_batch.shape, Y_batch[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02f19d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 10]) torch.Size([80, 2]) tensor([ 0.7863, -0.2995])\n",
      "torch.Size([10, 10]) torch.Size([10, 2]) tensor([1.1036, 1.3205])\n",
      "torch.Size([10, 10]) torch.Size([10, 2]) tensor([ 0.0376, -0.8211])\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use DataHandlerPT\n",
    "np.random.seed(0)\n",
    "_X = np.random.rand(100, 10)  # 100 samples, 10 features each\n",
    "_Y = np.random.rand(100, 2)  # 100 targets\n",
    "\n",
    "data_handler = DataHandlerPT(_X, _Y, scalerX=StandardScaler(), scalerY=StandardScaler())\n",
    "data_handler.split_and_scale(test_size=0.1, val_size=0.1, random_state=0)\n",
    "\n",
    "ds_train = data_handler.get_train()\n",
    "ds_val = data_handler.get_val()\n",
    "ds_test = data_handler.get_test()\n",
    "\n",
    "for ds in [ds_train, ds_val, ds_test]:\n",
    "    X, Y = ds[:]\n",
    "    print(X.shape, Y.shape, Y[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eb9a4232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "exp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "m1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "m2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "m3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__longest_strike_above_mean",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__autocorrelation__lag_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__approximate_entropy__m_2__r_0.7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__longest_strike_below_mean",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__autocorrelation__lag_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__approximate_entropy__m_2__r_0.9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__permutation_entropy__dimension_3__tau_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__autocorrelation__lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__permutation_entropy__dimension_5__tau_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__permutation_entropy__dimension_4__tau_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__permutation_entropy__dimension_6__tau_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__permutation_entropy__dimension_7__tau_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__cid_ce__normalize_True",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__approximate_entropy__m_2__r_0.3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__number_peaks__n_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__number_peaks__n_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__number_peaks__n_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__number_cwt_peaks__n_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__number_peaks__n_10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__ar_coefficient__coeff_8__k_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__number_cwt_peaks__n_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s1__spkt_welch_density__coeff_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__agg_autocorrelation__f_agg_\"median\"__maxlag_40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__approximate_entropy__m_2__r_0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__agg_autocorrelation__f_agg_\"mean\"__maxlag_40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__ar_coefficient__coeff_3__k_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__approximate_entropy__m_2__r_0.1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__lempel_ziv_complexity__bins_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__partial_autocorrelation__lag_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__fft_coefficient__attr_\"abs\"__coeff_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__agg_autocorrelation__f_agg_\"var\"__maxlag_40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "s1__spkt_welch_density__coeff_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d63f4a61-b31a-47be-83e4-a1b8a502e793",
       "rows": [
        [
         "E001",
         "150.2237162282709",
         "1176.177277778291",
         "1.142097497096118",
         "-0.3054339202505594",
         "-0.5191912937471133",
         "-0.07482931020721237",
         "0.1598964088207946",
         "0.385790122546617",
         "0.5903865308147479",
         "14",
         "0.7623960064154589",
         "0.2347346166610531",
         "14",
         "0.8923275547414669",
         "0.1627475159081164",
         "1.016163897369947",
         "0.9730124996338729",
         "0.9730124996338729",
         "1.62687847092397",
         "1.323937191565679",
         "1.924233458480636",
         "2.215079757527388",
         "3.966110221397809",
         "0.2054671462622681",
         "-0.226538711723462",
         "-0.2337969396502632",
         "-0.2313599744498629",
         "-0.2496215600475206",
         "11",
         "11",
         "11",
         "12",
         "10",
         "-0.1228645658353847",
         "-0.2871916578780337",
         "12",
         "2.302092584356073e-06",
         "-0.04029898618473704",
         "0.294575630574742",
         "-0.02381745749888618",
         "0.1839963654696146",
         "0.1585670576081162",
         "0.2041522491349481",
         "-0.3600840997659662",
         "0.2936172551085162",
         "0.4994878943759984",
         "5.88681152271281e-08",
         "55.46043367834409",
         "1.065916993455059",
         "114.5786204103125"
        ],
        [
         "E002",
         "102.5342678762004",
         "1483.654981916516",
         "1.104716419796098",
         "-0.2437852899127758",
         "-0.4542619780809531",
         "-0.02100206449903134",
         "0.2028355495861272",
         "0.4164225579112382",
         "0.6089720749981536",
         "14",
         "0.770760087739035",
         "0.222246210142254",
         "14",
         "0.8936165162838874",
         "0.1560670115588841",
         "0.9993568167921798",
         "0.9713377747746932",
         "0.9713377747746935",
         "1.576553073550272",
         "1.289890751104698",
         "1.858735405789931",
         "2.135705047559143",
         "3.6526435059868",
         "0.2110247401319967",
         "-0.2244198468351331",
         "-0.2325474580042485",
         "-0.2280495585317081",
         "-0.2444386143773333",
         "10",
         "9",
         "9",
         "10",
         "9",
         "-0.1251216792908884",
         "-0.278643948183462",
         "11",
         "9.194826079354894e-05",
         "0.005710727812269289",
         "0.295793386116199",
         "0.0174124077277948",
         "0.184369500523606",
         "0.1447418877366329",
         "0.2030075187969925",
         "-0.3443643252966841",
         "6.14237252208545",
         "0.4777432349844861",
         "3.64362055523439e-06",
         "50.64030573896383",
         "1.285665791352698",
         "124.6514837646304"
        ],
        [
         "E003",
         "119.8905490887243",
         "1254.897450653388",
         "2.162773409498691",
         "-0.3290060356266322",
         "-0.5434049971045741",
         "-0.09591338517658776",
         "0.1426122079089866",
         "0.3730020599120391",
         "0.5821514156665052",
         "14",
         "0.7581648639475573",
         "0.2394955454843397",
         "13",
         "0.8910329028051504",
         "0.165112565585219",
         "1.020465652695851",
         "0.9732011747853436",
         "0.9732011747853435",
         "1.646824878831804",
         "1.343150699207861",
         "1.944883653328339",
         "2.236309406751573",
         "3.682674589911052",
         "0.2017099991694988",
         "-0.2299484930997584",
         "-0.2383027291229635",
         "-0.2342132613799649",
         "-0.2523388214511478",
         "9",
         "9",
         "9",
         "10",
         "9",
         "-0.1218498437486562",
         "-0.2902894407037535",
         "11",
         "0.002991810076493899",
         "-0.06252100701744168",
         "0.2953766624528682",
         "-0.03807682374626591",
         "0.1840355025745247",
         "0.1442678316464963",
         "0.2081632653061224",
         "-0.3646107419088709",
         "26.78328344000789",
         "0.5064350830051291",
         "0.0001590028102571489",
         "50.83240472683809",
         "1.154859212683363",
         "57.01805417221681"
        ],
        [
         "E004",
         "162.8307992564844",
         "1302.043195135213",
         "1.30828321525042",
         "-0.0651521463136262",
         "-0.2664976926877177",
         "0.1389126502736655",
         "0.3371865864369897",
         "0.5214009296929024",
         "0.6838731666679987",
         "16",
         "0.8178274013703623",
         "0.1937549744108571",
         "16",
         "0.9176769485378873",
         "0.1370265745426402",
         "0.9726561048364449",
         "0.9792573362550936",
         "0.9792573362550935",
         "1.522951107576066",
         "1.249446870300736",
         "1.792685681282132",
         "2.058077147838571",
         "3.440933521168234",
         "0.2300116952585212",
         "-0.2135504176683748",
         "-0.2150938543416185",
         "-0.2220255651562478",
         "-0.2427030761830581",
         "9",
         "9",
         "9",
         "10",
         "9",
         "-0.1269822026600489",
         "-0.2818301171729558",
         "11",
         "0.03254871106161762",
         "0.167136898506159",
         "0.2838976837493383",
         "0.09874930838143854",
         "0.1872132457419277",
         "0.1373263951521655",
         "0.1936619718309859",
         "-0.3554414001104249",
         "33.22759074069934",
         "0.4605467208889374",
         "0.0007926165201968495",
         "62.47654543460142",
         "1.025160763802677",
         "132.2212175987509"
        ],
        [
         "E005",
         "165.72095638279",
         "1154.482313700376",
         "1.566829730087374",
         "-0.3048808371286578",
         "-0.5181766102806283",
         "-0.07483610968997173",
         "0.1593210142907042",
         "0.3847279896743889",
         "0.5890028422139049",
         "14",
         "0.7609243327125759",
         "0.2381097596952311",
         "14",
         "0.8910483643868621",
         "0.1626447113788911",
         "1.014791878416955",
         "0.9722267728214827",
         "0.9722267728214827",
         "1.62111225074021",
         "1.320327783744526",
         "1.916410952543579",
         "2.205328048547567",
         "3.995534195873079",
         "0.2072160931479998",
         "-0.2306634372538851",
         "-0.2403558289400577",
         "-0.233806167154005",
         "-0.2506967126737985",
         "11",
         "11",
         "11",
         "12",
         "10",
         "-0.1230299291182262",
         "-0.2868315494200753",
         "12",
         "0.005794605001799167",
         "-0.04382424818770635",
         "0.2887581856673982",
         "-0.0222890433765183",
         "0.1839782130968768",
         "0.1285455017839277",
         "0.1924398625429553",
         "-0.3575884147822471",
         "11.4394702754538",
         "0.4979403938074322",
         "0.0001462830650636705",
         "57.63443803240473",
         "1.043776221564284",
         "92.16026864580095"
        ]
       ],
       "shape": {
        "columns": 50,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>s1__autocorrelation__lag_8</th>\n",
       "      <th>s1__autocorrelation__lag_9</th>\n",
       "      <th>s1__autocorrelation__lag_7</th>\n",
       "      <th>s1__autocorrelation__lag_6</th>\n",
       "      <th>s1__autocorrelation__lag_5</th>\n",
       "      <th>s1__autocorrelation__lag_4</th>\n",
       "      <th>s1__longest_strike_above_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>s1__ar_coefficient__coeff_3__k_10</th>\n",
       "      <th>s1__approximate_entropy__m_2__r_0.1</th>\n",
       "      <th>s1__lempel_ziv_complexity__bins_3</th>\n",
       "      <th>s1__partial_autocorrelation__lag_4</th>\n",
       "      <th>s1__fft_coefficient__attr_\"abs\"__coeff_7</th>\n",
       "      <th>s1__agg_autocorrelation__f_agg_\"var\"__maxlag_40</th>\n",
       "      <th>s1__spkt_welch_density__coeff_2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E001</th>\n",
       "      <td>150.223716</td>\n",
       "      <td>1176.177278</td>\n",
       "      <td>1.142097</td>\n",
       "      <td>-0.305434</td>\n",
       "      <td>-0.519191</td>\n",
       "      <td>-0.074829</td>\n",
       "      <td>0.159896</td>\n",
       "      <td>0.385790</td>\n",
       "      <td>0.590387</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183996</td>\n",
       "      <td>0.158567</td>\n",
       "      <td>0.204152</td>\n",
       "      <td>-0.360084</td>\n",
       "      <td>0.293617</td>\n",
       "      <td>0.499488</td>\n",
       "      <td>5.886812e-08</td>\n",
       "      <td>55.460434</td>\n",
       "      <td>1.065917</td>\n",
       "      <td>114.578620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E002</th>\n",
       "      <td>102.534268</td>\n",
       "      <td>1483.654982</td>\n",
       "      <td>1.104716</td>\n",
       "      <td>-0.243785</td>\n",
       "      <td>-0.454262</td>\n",
       "      <td>-0.021002</td>\n",
       "      <td>0.202836</td>\n",
       "      <td>0.416423</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184370</td>\n",
       "      <td>0.144742</td>\n",
       "      <td>0.203008</td>\n",
       "      <td>-0.344364</td>\n",
       "      <td>6.142373</td>\n",
       "      <td>0.477743</td>\n",
       "      <td>3.643621e-06</td>\n",
       "      <td>50.640306</td>\n",
       "      <td>1.285666</td>\n",
       "      <td>124.651484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E003</th>\n",
       "      <td>119.890549</td>\n",
       "      <td>1254.897451</td>\n",
       "      <td>2.162773</td>\n",
       "      <td>-0.329006</td>\n",
       "      <td>-0.543405</td>\n",
       "      <td>-0.095913</td>\n",
       "      <td>0.142612</td>\n",
       "      <td>0.373002</td>\n",
       "      <td>0.582151</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184036</td>\n",
       "      <td>0.144268</td>\n",
       "      <td>0.208163</td>\n",
       "      <td>-0.364611</td>\n",
       "      <td>26.783283</td>\n",
       "      <td>0.506435</td>\n",
       "      <td>1.590028e-04</td>\n",
       "      <td>50.832405</td>\n",
       "      <td>1.154859</td>\n",
       "      <td>57.018054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E004</th>\n",
       "      <td>162.830799</td>\n",
       "      <td>1302.043195</td>\n",
       "      <td>1.308283</td>\n",
       "      <td>-0.065152</td>\n",
       "      <td>-0.266498</td>\n",
       "      <td>0.138913</td>\n",
       "      <td>0.337187</td>\n",
       "      <td>0.521401</td>\n",
       "      <td>0.683873</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187213</td>\n",
       "      <td>0.137326</td>\n",
       "      <td>0.193662</td>\n",
       "      <td>-0.355441</td>\n",
       "      <td>33.227591</td>\n",
       "      <td>0.460547</td>\n",
       "      <td>7.926165e-04</td>\n",
       "      <td>62.476545</td>\n",
       "      <td>1.025161</td>\n",
       "      <td>132.221218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E005</th>\n",
       "      <td>165.720956</td>\n",
       "      <td>1154.482314</td>\n",
       "      <td>1.566830</td>\n",
       "      <td>-0.304881</td>\n",
       "      <td>-0.518177</td>\n",
       "      <td>-0.074836</td>\n",
       "      <td>0.159321</td>\n",
       "      <td>0.384728</td>\n",
       "      <td>0.589003</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183978</td>\n",
       "      <td>0.128546</td>\n",
       "      <td>0.192440</td>\n",
       "      <td>-0.357588</td>\n",
       "      <td>11.439470</td>\n",
       "      <td>0.497940</td>\n",
       "      <td>1.462831e-04</td>\n",
       "      <td>57.634438</td>\n",
       "      <td>1.043776</td>\n",
       "      <td>92.160269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              m1           m2        m3  s1__autocorrelation__lag_8  \\\n",
       "exp                                                                   \n",
       "E001  150.223716  1176.177278  1.142097                   -0.305434   \n",
       "E002  102.534268  1483.654982  1.104716                   -0.243785   \n",
       "E003  119.890549  1254.897451  2.162773                   -0.329006   \n",
       "E004  162.830799  1302.043195  1.308283                   -0.065152   \n",
       "E005  165.720956  1154.482314  1.566830                   -0.304881   \n",
       "\n",
       "      s1__autocorrelation__lag_9  s1__autocorrelation__lag_7  \\\n",
       "exp                                                            \n",
       "E001                   -0.519191                   -0.074829   \n",
       "E002                   -0.454262                   -0.021002   \n",
       "E003                   -0.543405                   -0.095913   \n",
       "E004                   -0.266498                    0.138913   \n",
       "E005                   -0.518177                   -0.074836   \n",
       "\n",
       "      s1__autocorrelation__lag_6  s1__autocorrelation__lag_5  \\\n",
       "exp                                                            \n",
       "E001                    0.159896                    0.385790   \n",
       "E002                    0.202836                    0.416423   \n",
       "E003                    0.142612                    0.373002   \n",
       "E004                    0.337187                    0.521401   \n",
       "E005                    0.159321                    0.384728   \n",
       "\n",
       "      s1__autocorrelation__lag_4  s1__longest_strike_above_mean  ...  \\\n",
       "exp                                                              ...   \n",
       "E001                    0.590387                             14  ...   \n",
       "E002                    0.608972                             14  ...   \n",
       "E003                    0.582151                             14  ...   \n",
       "E004                    0.683873                             16  ...   \n",
       "E005                    0.589003                             14  ...   \n",
       "\n",
       "      s1__ar_coefficient__coeff_3__k_10  s1__approximate_entropy__m_2__r_0.1  \\\n",
       "exp                                                                            \n",
       "E001                           0.183996                             0.158567   \n",
       "E002                           0.184370                             0.144742   \n",
       "E003                           0.184036                             0.144268   \n",
       "E004                           0.187213                             0.137326   \n",
       "E005                           0.183978                             0.128546   \n",
       "\n",
       "      s1__lempel_ziv_complexity__bins_3  s1__partial_autocorrelation__lag_4  \\\n",
       "exp                                                                           \n",
       "E001                           0.204152                           -0.360084   \n",
       "E002                           0.203008                           -0.344364   \n",
       "E003                           0.208163                           -0.364611   \n",
       "E004                           0.193662                           -0.355441   \n",
       "E005                           0.192440                           -0.357588   \n",
       "\n",
       "      s1__fft_coefficient__attr_\"abs\"__coeff_7  \\\n",
       "exp                                              \n",
       "E001                                  0.293617   \n",
       "E002                                  6.142373   \n",
       "E003                                 26.783283   \n",
       "E004                                 33.227591   \n",
       "E005                                 11.439470   \n",
       "\n",
       "      s1__agg_autocorrelation__f_agg_\"var\"__maxlag_40  \\\n",
       "exp                                                     \n",
       "E001                                         0.499488   \n",
       "E002                                         0.477743   \n",
       "E003                                         0.506435   \n",
       "E004                                         0.460547   \n",
       "E005                                         0.497940   \n",
       "\n",
       "      s1__spkt_welch_density__coeff_2         y1        y2          y3  \n",
       "exp                                                                     \n",
       "E001                     5.886812e-08  55.460434  1.065917  114.578620  \n",
       "E002                     3.643621e-06  50.640306  1.285666  124.651484  \n",
       "E003                     1.590028e-04  50.832405  1.154859   57.018054  \n",
       "E004                     7.926165e-04  62.476545  1.025161  132.221218  \n",
       "E005                     1.462831e-04  57.634438  1.043776   92.160269  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"data.xlsx\", index_col=\"exp\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "688bf5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 47)\n",
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "_X = df.iloc[:, :-3].values\n",
    "_Y = df.iloc[:, -3:].values\n",
    "print(_X.shape)\n",
    "print(_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8283ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandlerPT(\n",
    "    _X=_X, _Y=_Y, scalerX=StandardScaler(), scalerY=StandardScaler()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f86dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "torch.Size([16, 47]) torch.Size([16, 3]) tensor([ 0.0655, -0.2978, -0.1652])\n",
      "torch.Size([16, 47]) torch.Size([16, 3]) tensor([ 0.3878, -1.5409, -0.1069])\n",
      "torch.Size([16, 47]) torch.Size([16, 3]) tensor([ 0.7325, -0.6939,  1.2493])\n",
      "torch.Size([16, 47]) torch.Size([16, 3]) tensor([ 0.5371, -0.9610,  1.2404])\n",
      "torch.Size([6, 47]) torch.Size([6, 3]) tensor([ 0.0376,  0.1571, -1.0112])\n",
      "Val\n",
      "torch.Size([10, 47]) torch.Size([10, 3]) tensor([0.0535, 0.0006, 0.0820])\n"
     ]
    }
   ],
   "source": [
    "data_handler.split_and_scale(test_size=0.2, val_size=0.1, random_state=0)\n",
    "ds_train = data_handler.get_train()\n",
    "ds_val = data_handler.get_val()\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=16, shuffle=True)\n",
    "loader_val = DataLoader(ds_val, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"Train\")\n",
    "for X_batch, Y_batch in loader_train:\n",
    "    print(X_batch.shape, Y_batch.shape, Y_batch[0, :])\n",
    "\n",
    "print(\"Val\")\n",
    "for X_batch, Y_batch in loader_val:\n",
    "    print(X_batch.shape, Y_batch.shape, Y_batch[0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
